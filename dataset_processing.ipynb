{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.10.1\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HighBoots', 'Sneakers', 'MidcalfSneakers', 'Boots', 'Booties', 'Flats', 'Sandals', 'Slippers', 'HighSandals', 'MidcalfBoots', 'Pumps(Heels)', 'MidcalfBooties', 'Clogs', 'HighBooties', 'MidcalfSandals', 'Espadrilles']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Add dataset folder to the 'data_dir' variable.\n",
    "In this example, dataset is in './raw' folder.\n",
    "\"\"\"\n",
    "data_dir = './raw'\n",
    "categories = [x for x in os.listdir(data_dir) if x!='.DS_Store']\n",
    "print(categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!----- Padding and Cropping ------->\n",
      "Category: HighBoots\n",
      "Number of Train Images in HighBoots category: 965 \n",
      "Number of Test Images in HighBoots category: 53\n",
      "Number of Validation Images in HighBoots category: 55\n",
      "Total files in HighBoots category: 1073\n",
      "Category: Sneakers\n",
      "Number of Train Images in Sneakers category: 4303 \n",
      "Number of Test Images in Sneakers category: 239\n",
      "Number of Validation Images in Sneakers category: 240\n",
      "Total files in Sneakers category: 4782\n",
      "Category: MidcalfSneakers\n",
      "Number of Train Images in MidcalfSneakers category: 4 \n",
      "Number of Test Images in MidcalfSneakers category: 0\n",
      "Number of Validation Images in MidcalfSneakers category: 1\n",
      "Total files in MidcalfSneakers category: 5\n",
      "Category: Boots\n",
      "Number of Train Images in Boots category: 201 \n",
      "Number of Test Images in Boots category: 11\n",
      "Number of Validation Images in Boots category: 12\n",
      "Total files in Boots category: 224\n",
      "Category: Booties\n",
      "Number of Train Images in Booties category: 3837 \n",
      "Number of Test Images in Booties category: 213\n",
      "Number of Validation Images in Booties category: 214\n",
      "Total files in Booties category: 4264\n",
      "Category: Flats\n",
      "Number of Train Images in Flats category: 3669 \n",
      "Number of Test Images in Flats category: 203\n",
      "Number of Validation Images in Flats category: 205\n",
      "Total files in Flats category: 4077\n",
      "Category: Sandals\n",
      "Number of Train Images in Sandals category: 8460 \n",
      "Number of Test Images in Sandals category: 470\n",
      "Number of Validation Images in Sandals category: 470\n",
      "Total files in Sandals category: 9400\n",
      "Category: Slippers\n",
      "Number of Train Images in Slippers category: 53 \n",
      "Number of Test Images in Slippers category: 2\n",
      "Number of Validation Images in Slippers category: 4\n",
      "Total files in Slippers category: 59\n",
      "Category: HighSandals\n",
      "Number of Train Images in HighSandals category: 59 \n",
      "Number of Test Images in HighSandals category: 3\n",
      "Number of Validation Images in HighSandals category: 4\n",
      "Total files in HighSandals category: 66\n",
      "Category: MidcalfBoots\n",
      "Number of Train Images in MidcalfBoots category: 612 \n",
      "Number of Test Images in MidcalfBoots category: 34\n",
      "Number of Validation Images in MidcalfBoots category: 35\n",
      "Total files in MidcalfBoots category: 681\n",
      "Category: Pumps(Heels)\n",
      "Number of Train Images in Pumps(Heels) category: 2646 \n",
      "Number of Test Images in Pumps(Heels) category: 147\n",
      "Number of Validation Images in Pumps(Heels) category: 147\n",
      "Total files in Pumps(Heels) category: 2940\n",
      "Category: MidcalfBooties\n",
      "Number of Train Images in MidcalfBooties category: 174 \n",
      "Number of Test Images in MidcalfBooties category: 9\n",
      "Number of Validation Images in MidcalfBooties category: 11\n",
      "Total files in MidcalfBooties category: 194\n",
      "Category: Clogs\n",
      "Number of Train Images in Clogs category: 92 \n",
      "Number of Test Images in Clogs category: 5\n",
      "Number of Validation Images in Clogs category: 6\n",
      "Total files in Clogs category: 103\n",
      "Category: HighBooties\n",
      "Number of Train Images in HighBooties category: 17 \n",
      "Number of Test Images in HighBooties category: 0\n",
      "Number of Validation Images in HighBooties category: 2\n",
      "Total files in HighBooties category: 19\n",
      "Category: MidcalfSandals\n",
      "Number of Train Images in MidcalfSandals category: 23 \n",
      "Number of Test Images in MidcalfSandals category: 1\n",
      "Number of Validation Images in MidcalfSandals category: 2\n",
      "Total files in MidcalfSandals category: 26\n",
      "Category: Espadrilles\n",
      "Number of Train Images in Espadrilles category: 1210 \n",
      "Number of Test Images in Espadrilles category: 67\n",
      "Number of Validation Images in Espadrilles category: 68\n",
      "Total files in Espadrilles category: 1345\n",
      "Padding & Cropping Image: Data Processing Completed!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "_train : % of images for training\n",
    "_test : % of images for testing\n",
    "_validating : % of images for validating\n",
    "\n",
    "Make sure to sum of _train, _test, _validate variable to 100.\n",
    "\n",
    "height, width, left, top, right, bottom values are calculated to create 512 x 512 image\n",
    "\n",
    "\"\"\"\n",
    "import image_helper\n",
    "\n",
    "WantedToReloadData = 1\n",
    "\n",
    "_train = 90\n",
    "_test = 5\n",
    "_validation = 5\n",
    "\n",
    "#By Default, use crop 1 and padding 1\n",
    "# If you want to crop, use 1, otherwise 0.\n",
    "crop = 1\n",
    "# If you want to padding, use 1, otherwise 0.\n",
    "padding = 1\n",
    "\n",
    "if WantedToReloadData:\n",
    "    height = 64\n",
    "    width = 64\n",
    "    left = 40\n",
    "    top = 40\n",
    "    right = 552\n",
    "    bottom = 552\n",
    "    if _train + _test + _validation > 100 or _train + _test + _validation < 100:\n",
    "        print(\"Sum of Train, Test, Validation values must be 100.\")\n",
    "    elif _train + _test + _validation == 100:\n",
    "        if padding and crop:\n",
    "            print(\"<!----- Padding and Cropping ------->\")\n",
    "            image_helper.divide_dataset_padding_crop(_train, _test, _validation, data_dir, categories, left, top, right, bottom)\n",
    "        elif (not padding) and (not crop):\n",
    "            print(\"<!----- Dividing Data for Test, Train and Validate ------->\")\n",
    "            image_helper.divide_dataset(_train, _test, _validation, data_dir, categories, width, height)\n",
    "        elif crop and (not padding):\n",
    "            print(\"<!----- Cropping ------->\")\n",
    "            image_helper.divide_dataset_crop(_train, _test, _validation, data_dir, categories, left, top, right, bottom)\n",
    "        elif padding and (not crop):\n",
    "            print(\"<!----- Padding ------->\")\n",
    "            image_helper.divide_dataset_padding(_train, _test, _validation, data_dir, categories, left, top, right, bottom)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data_files'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This step moves images from 'raw_data' folder to 'data_files' folder which is used in training step\n",
    "\"\"\"\n",
    "import shutil\n",
    "src = \"./raw_data/train\"\n",
    "dest = \"./data_files\"\n",
    "if os.path.exists(dest):\n",
    "    print(\"Entered!\")\n",
    "    shutil.rmtree(dest)\n",
    "\n",
    "shutil.copytree(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
